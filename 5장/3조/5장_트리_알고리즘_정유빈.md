# 용어
- 사분위수 : 데이터를 순서대로 4등분 한 값   
   예를 들어, 2사분위수(중간값)는 데이터를 일렬로 늘어놓았을 때 정중앙의 값. 만약 데이터의 개수가 짝수라 중앙값을 선택할 수 없다면 가운데 2개의 평균값을 사용한다
- StandardScaler 클래스 : 모든 feature들을 평균:0, 분산:1 로 조정(표준화 하기)
- 불순도 : 결정 트리가 최적의 질문을 찾기 위한 기준
- 정보 이득 : 부모 노드와 자식 노드의 불순도 차이(결정 트리 알고리즘은 정보 이득이 최대화되도록 학습)
- 특성 중요도 : 결정 트리에 사용된 특성이 불순도를 감소하는데 기여한 정도를 나타내는 값
- 검증 세트 : 하이퍼파라미터 튜닝을 위해 모델을 평가할 때, 테스트 세트를 사용하지 않기 위해 훈련 세트에서 다시 떼어 낸 데이터 세트
- 교차 검증 : 훈련 세트를 여러 폴드로 나눈 다음 한 폴드가 검증 세트의 역할을 하고 나머지 폴드에서는 모델을 훈련 한다. 이런식으로 모든 폴드에 대해 검증 점수를 얻어 평균하는 방법
- 그리드 서치 : 하이퍼파라미터 탐색을 자동화해 주는 도구. 탐색할 매개변수를 나열하면 교차 거즘을 수행하여 가장 좋은 검증 점수의 매개변수 조합을 선택
- 랜덤 서치 : 연속된 매개변수 값을 탐색할때 유용. 탐색할 값을 직접 나열하는 것이 아닌 탐색 값을 샘플링할 수 있는 확률 분포 객체를 전달 

# 5-1 결정 트리
: 결정 트리는 특정 기준(질문)을 따라 데이터를 구분 짓는다. 결정 트리의 가장 첫 번째 기준은 트리에서 최초 깊이인 루트 노드(Root node)에서 시작하며, 트리가 하위 깊이로 깊어지면서 생성되는 새로운 분류 기준이 되는 질문을 노드(Node)라고 말하며, 더 이상 분기가 되지 않는 마지막 노드를 'Terminal' 또는 'Leaf Node' 라고 한다.

- #### 데이터에 누락된 값이 있다면?  
  : 그 데이터를 버리거나 평균값으로 채운 후 사용할 수 있다.

- 어떤 클래스의 비율이 높아지면 점점 진한 색으로 표시한다
- #### 결정 트리에서 예측하는 방법
   : 리프 노드에서 가장 많은 클래스가 예측 클래스가 된다.

- #### 결정 트리의 장점
   : 표준화 전처리 과정이 필요가 없다.    
     특성 중요도를 계산해준다  
  (특성 중요도는 각 노드의 정보 이득과 전체 샘플에 대한 비율을 곱한 후 특성별로 더하여 계산)

> 결정 트리를 회귀 문제에 적용하면 리프 노드에 도달한 샘플의 타깃을 평균하여 예측값으로 사용

### 불순도
: gini는 지니 불순도(Gini inpurity)를 의미한다.

지니 불순도 = 1 - (음성 클래스 비율^2 + 양성 클래스 비율^2)  
> ex. 10개의 구슬 중 파란구슬 3개   
> 1-((3/10)^2 + (7/10)^2) = 0.42    
> 42% 정도의 불순도를 구한다... 잘 분류되었으면 0 에 가까워진다  

- 어떤 노드의 두 클래스 비율이 정확히 1/2 씩이라면 지니 불순도는 0.5가 되어 최악의 상황이 된다  
- 노드에 하나의 클래스만 있다면 지니 불순도는 0이 되어 가장 작습니다. 이러한 노드를 순수 노드라고 부른다
- 노드를 순수하게 나눌수록 정보이득이 커진다

- 결정 트리 모델은 부모 노드와 자식 노드의 불순도 차이가 가능한 크도록 트리를 성장 시킨다.
> 부모의 불순도 - (왼쪽 노드 샘플 수 / 부모의 샘플 수) x 왼쪽 노드 불순도 - (오른쪽 노드 샘플 수 / 부모의 샘플 수) x 오른쪽 노드 불순도

#### 이러한 부모와 자식 노드 사이의 불순도 차이를 정보 이득이라고 부른다. 

- DecisionTreeClassifier 클래스에서 criterion = 'entropy'를 지정하여 엔트로피 불순도를 사용할 수 있다
- 엔트로피 불순도도 노드의 클래스 비율을 사용하지만, 지니 불순도처럼 제곱이 아닌 밑이 2인 로그를 사용하여 곱한다.
> 음성 클래스 비율 x log(음성 클래스 비율) - 양성 클래스 비율 x log(양성 클래스 비율)

### 가지치기
: 가지치기를 하는 간단한 방법은 트리의 최대 깊이를 지정하는 것이다.(맨 위의 부모노드는 깊이 : 0)

# 5-2 교차 검증과 그리드 서치

> ### 문제 발생 : 테스트 세트를 사용해 자꾸 성능을 확인하다 보면 점점 테스트 세트에 맞추게 된다

### 검증 세트
: 훈련 세트를 또 나누어서 검증 세트를 만들기
이전) 20% : 테스트 , 80% : 훈련
80%의 훈련 세트 중에서 20%를 떼어 내어 검증 세트로 만들기
- 60 : 20 : 20 = 훈련 : 검증 : 테스트
> #### 테스트 세트와 검증 세트에 얼마나 많은 샘플을 덜어놔야 하는지?
> 보통 20~30%를 테스트 세트와 검증 세트로 떼어 놓는다. 하지만, 훈련 데이터가 아무 많다면 단 몇 %만 떼어 놓아도 전체 데이터를 대표하는데 문제가 없다.

### 교차 검증
: 교차 검증은 검증 세트를 떼어 내어 평가하는 과정을 여러 번 반복하는 것    
<img width="80%" src="https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/73346564/e272c58f-0bd2-40c7-8dbb-5c04875ecceb"/>

> ### 3-폴드 교차 검증
> 훈련 세트를 세 부분으로 나눠서 교차 검증을 수행하는 것.
> 통칭 k-폴드 교차 검증(k-fold cross validation)이라고 하며, 훈련 세트를 몇 부분으로 나누냐에 따라 다르게 부른다
> k-겹 교차 검증이라고도 부른다.    
> 보통 5-폴드 교차 검증이나 10-폴드 교차 검증을 많이 사용한다
> 이렇게 하면 데이터의 80~90% 까지 훈련에 사용할 수 있으며, 검증 세트가 줄어들지만 각 폴드에서 계산한 검증 점수를 평균하기 때문에 안정된 점수로 생각한다.

- cross_calidate() 교차 검증 함수 in 사이킷런
  : 평가할 모델 객체를 첫 번째 매개변수로 전달. 그다음 앞에서처럼 직접 검증 세트를 떼어 내지 않고 훈련 세트 전체를 cross_validate() 함수에 전달한다.

> ### 교차 검증의 최종 점수는 test_score 키에 담긴 5개의 점수를 평균하여 얻을 수 있다
> ### 이름은 test_score지만 검증 폴드의 점수이다!!

### 하이퍼파라미터 튜닝
> 사람의 개입 없이 하이퍼파라미터 튜닝을 자동으로 수행하는 기술을 'AutoML' 이라고 부른다.

1. 탐색할 매개변수를 지정
2. 훈련 세트에서 그리드 서치를 수행하여 최상의 평균 검증 점수가 나오는 매개변수 조합을 찾기. 이 조합은 그리드 서치 객체에 저장된다.
3. 그리드 서치는 최상의 매개변수에서 (교차 검증에 사용한 훈련 세트가 아니라) 전체 훈련 세트를 사용해 최종 모델을 훈련한다.
4. 위의 모델도 그리드 서치 객체에 저장된다.

### 랜덤 서치
: 매개변수 값의 목록을 전달하는 것이 아니라 매개변수를 샘플링할 수 있는 확률 분포 객체를 전달한다.

# 5-3. 트리의 앙상블

### 앙상블 학습
: 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 알고리즘이며, 여러 개의 분류기를 생성하고 각 예측들을 결합함으로써 보다 정확한 예측을 도출하는 기법      
이 알고리즘은 대부분 결정 트리를 기반으로 만들어져 있다. 


### 랜덤 포레스트
- 데이터를 만드는 방법(부트스트랩 샘플, )
#### 부트스트랩 샘플
: 입력한 훈련 데이터에서 랜덤하게 샘플을 추출하여 훈련 데이터 만들기. 이때 한 샘플이 중복되어 추출될 수 있다
ex. 1000개의 가방에서 100개씩 샘플을 뽑는다면, 
