# 용어
- 사분위수 : 데이터를 순서대로 4등분 한 값   
   예를 들어, 2사분위수(중간값)는 데이터를 일렬로 늘어놓았을 때 정중앙의 값. 만약 데이터의 개수가 짝수라 중앙값을 선택할 수 없다면 가운데 2개의 평균값을 사용한다
- StandardScaler 클래스 : 모든 feature들을 평균:0, 분산:1 로 조정(표준화 하기)

# 5-1 결정 트리
: 결정 트리는 특정 기준(질문)을 따라 데이터를 구분 짓는다. 결정 트리의 가장 첫 번째 기준은 트리에서 최초 깊이인 루트 노드(Root node)에서 시작하며, 트리가 하위 깊이로 깊어지면서 생성되는 새로운 분류 기준이 되는 질문을 노드(Node)라고 말하며, 더 이상 분기가 되지 않는 마지막 노드를 'Terminal' 또는 'Leaf Node' 라고 한다.

- #### 데이터에 누락된 값이 있다면?  
  : 그 데이터를 버리거나 평균값으로 채운 후 사용할 수 있다.

- 어떤 클래스의 비율이 높아지면 점점 진한 색으로 표시한다
- #### 결정 트리에서 예측하는 방법
   : 리프 노드에서 가장 많은 클래스가 예측 클래스가 된다.

> 결정 트리를 회귀 문제에 적용하면 리프 노드에 도달한 샘플의 타깃을 평균하여 예측값으로 사용

### 불순도
: gini는 지니 불순도(Gini inpurity)를 의미한다.

지니 불순도 = 1 - (음성 클래스 비율^2 + 양성 클래스 비율^2)  
> ex. 10개의 구슬 중 파란구슬 3개   
> 1-((3/10)^2 + (7/10)^2) = 0.42    
> 42% 정도의 불순도를 구한다... 잘 분류되었으면 0 에 가까워진다  

- 어떤 노드의 두 클래스 비율이 정확히 1/2 씩이라면 지니 불순도는 0.5가 되어 최악의 상황이 된다  
- 노드에 하나의 클래스만 있다면 지니 불순도는 0이 되어 가장 작습니다. 이러한 노드를 순수 노드라고 부른다


- 결정 트리 모델은 부모 노드와 자식 노드의 불순도 차이가 가능한 크도록 트리를 성장 시킨다.
> 부모의 불순도 - (왼쪽 노드 샘플 수 / 부모의 샘플 수) x 왼쪽 노드 불순도 - (오른쪽 노드 샘플 수 / 부모의 샘플 수) x 오른쪽 노드 불순도

#### 이러한 부모와 자식 노드 사이의 불순도 차이를 정보 이득이라고 부른다. 
